{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "NMf2-2mkj6Js",
        "outputId": "72b60a08-792f-442a-91f3-f34d5884ec0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/159.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.0\n",
            "Fetching data for MMM (3M)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-52fb16d9c59f>:82: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  financial_data = pd.concat([financial_data, pd.DataFrame({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching data for AOS (A. O. Smith)...\n",
            "Fetching data for ABT (Abbott Laboratories)...\n",
            "Fetching data for ABBV (AbbVie)...\n",
            "Fetching data for ACN (Accenture)...\n",
            "Fetching data for ADBE (Adobe Inc.)...\n",
            "Fetching data for AMD (Advanced Micro Devices)...\n",
            "Fetching data for AES (AES Corporation)...\n",
            "Fetching data for AFL (Aflac)...\n",
            "Fetching data for A (Agilent Technologies)...\n",
            "Fetching data for APD (Air Products)...\n",
            "Fetching data for ABNB (Airbnb)...\n",
            "Fetching data for AKAM (Akamai Technologies)...\n",
            "Fetching data for ALB (Albemarle Corporation)...\n",
            "Fetching data for ARE (Alexandria Real Estate Equities)...\n",
            "Fetching data for ALGN (Align Technology)...\n",
            "Fetching data for ALLE (Allegion)...\n",
            "Fetching data for LNT (Alliant Energy)...\n",
            "Fetching data for ALL (Allstate)...\n",
            "Fetching data for GOOGL (Alphabet Inc. (Class A))...\n",
            "Fetching data for GOOG (Alphabet Inc. (Class C))...\n",
            "Fetching data for MO (Altria)...\n",
            "Fetching data for AMZN (Amazon)...\n",
            "Fetching data for AMCR (Amcor)...\n",
            "Fetching data for AEE (Ameren)...\n",
            "Fetching data for AAL (American Airlines Group)...\n",
            "Fetching data for AEP (American Electric Power)...\n",
            "Fetching data for AXP (American Express)...\n",
            "Fetching data for AIG (American International Group)...\n",
            "Fetching data for AMT (American Tower)...\n",
            "Fetching data for AWK (American Water Works)...\n",
            "Fetching data for AMP (Ameriprise Financial)...\n",
            "Fetching data for AME (Ametek)...\n",
            "Fetching data for AMGN (Amgen)...\n",
            "Fetching data for APH (Amphenol)...\n",
            "Fetching data for ADI (Analog Devices)...\n",
            "Fetching data for ANSS (Ansys)...\n",
            "Fetching data for AON (Aon)...\n",
            "Fetching data for APA (APA Corporation)...\n",
            "Fetching data for AAPL (Apple Inc.)...\n",
            "Fetching data for AMAT (Applied Materials)...\n",
            "Fetching data for APTV (Aptiv)...\n",
            "Fetching data for ACGL (Arch Capital Group)...\n",
            "Fetching data for ADM (Archer Daniels Midland)...\n",
            "Fetching data for ANET (Arista Networks)...\n",
            "Fetching data for AJG (Arthur J. Gallagher & Co.)...\n",
            "Fetching data for AIZ (Assurant)...\n",
            "Fetching data for T (AT&T)...\n",
            "Fetching data for ATO (Atmos Energy)...\n",
            "Fetching data for ADSK (Autodesk)...\n",
            "Fetching data for ADP (Automatic Data Processing)...\n",
            "Fetching data for AZO (AutoZone)...\n",
            "Fetching data for AVB (AvalonBay Communities)...\n",
            "Fetching data for AVY (Avery Dennison)...\n",
            "Fetching data for AXON (Axon Enterprise)...\n",
            "Fetching data for BKR (Baker Hughes)...\n",
            "Fetching data for BALL (Ball Corporation)...\n",
            "Fetching data for BAC (Bank of America)...\n",
            "Fetching data for BK (BNY Mellon)...\n",
            "Fetching data for BBWI (Bath & Body Works, Inc.)...\n",
            "Fetching data for BAX (Baxter International)...\n",
            "Fetching data for BDX (Becton Dickinson)...\n",
            "Fetching data for BRK.B (Berkshire Hathaway)...\n",
            "Fetching data for BBY (Best Buy)...\n",
            "Fetching data for BIO (Bio-Rad Laboratories)...\n",
            "Fetching data for TECH (Bio-Techne)...\n",
            "Fetching data for BIIB (Biogen)...\n",
            "Fetching data for BLK (BlackRock)...\n",
            "Fetching data for BX (Blackstone Inc.)...\n",
            "Fetching data for BA (Boeing)...\n",
            "Fetching data for BKNG (Booking Holdings)...\n",
            "Fetching data for BWA (BorgWarner)...\n",
            "Fetching data for BSX (Boston Scientific)...\n",
            "Fetching data for BMY (Bristol Myers Squibb)...\n",
            "Fetching data for AVGO (Broadcom)...\n",
            "Fetching data for BR (Broadridge Financial Solutions)...\n",
            "Fetching data for BRO (Brown & Brown)...\n",
            "Fetching data for BF.B (Brown–Forman)...\n",
            "Fetching data for BLDR (Builders FirstSource)...\n",
            "Fetching data for BG (Bunge Global)...\n",
            "Fetching data for BXP (BXP, Inc.)...\n",
            "Fetching data for CHRW (C.H. Robinson)...\n",
            "Fetching data for CDNS (Cadence Design Systems)...\n",
            "Fetching data for CZR (Caesars Entertainment)...\n",
            "Fetching data for CPT (Camden Property Trust)...\n",
            "Fetching data for CPB (Campbell Soup Company)...\n",
            "Fetching data for COF (Capital One)...\n",
            "Fetching data for CAH (Cardinal Health)...\n",
            "Fetching data for KMX (CarMax)...\n",
            "Fetching data for CCL (Carnival)...\n",
            "Fetching data for CARR (Carrier Global)...\n",
            "Fetching data for CTLT (Catalent)...\n",
            "Fetching data for CAT (Caterpillar Inc.)...\n",
            "Fetching data for CBOE (Cboe Global Markets)...\n",
            "Fetching data for CBRE (CBRE Group)...\n",
            "Fetching data for CDW (CDW)...\n",
            "Fetching data for CE (Celanese)...\n",
            "Fetching data for COR (Cencora)...\n",
            "Fetching data for CNC (Centene Corporation)...\n",
            "Fetching data for CNP (CenterPoint Energy)...\n",
            "Fetching data for CF (CF Industries)...\n",
            "Fetching data for CRL (Charles River Laboratories)...\n",
            "Fetching data for SCHW (Charles Schwab Corporation)...\n",
            "Fetching data for CHTR (Charter Communications)...\n",
            "Fetching data for CVX (Chevron Corporation)...\n",
            "Fetching data for CMG (Chipotle Mexican Grill)...\n",
            "Fetching data for CB (Chubb Limited)...\n",
            "Fetching data for CHD (Church & Dwight)...\n",
            "Fetching data for CI (Cigna)...\n",
            "Fetching data for CINF (Cincinnati Financial)...\n",
            "Fetching data for CTAS (Cintas)...\n",
            "Fetching data for CSCO (Cisco)...\n",
            "Fetching data for C (Citigroup)...\n",
            "Fetching data for CFG (Citizens Financial Group)...\n",
            "Fetching data for CLX (Clorox)...\n",
            "Fetching data for CME (CME Group)...\n",
            "Fetching data for CMS (CMS Energy)...\n",
            "Fetching data for KO (Coca-Cola Company (The))...\n",
            "Fetching data for CTSH (Cognizant)...\n",
            "Fetching data for CL (Colgate-Palmolive)...\n",
            "Fetching data for CMCSA (Comcast)...\n",
            "Fetching data for CAG (Conagra Brands)...\n",
            "Fetching data for COP (ConocoPhillips)...\n",
            "Fetching data for ED (Consolidated Edison)...\n",
            "Fetching data for STZ (Constellation Brands)...\n",
            "Fetching data for CEG (Constellation Energy)...\n",
            "Fetching data for COO (Cooper Companies (The))...\n",
            "Fetching data for CPRT (Copart)...\n",
            "Fetching data for GLW (Corning Inc.)...\n",
            "Fetching data for CPAY (Corpay)...\n",
            "Fetching data for CTVA (Corteva)...\n",
            "Fetching data for CSGP (CoStar Group)...\n",
            "Fetching data for COST (Costco)...\n",
            "Fetching data for CTRA (Coterra)...\n",
            "Fetching data for CRWD (CrowdStrike)...\n",
            "Fetching data for CCI (Crown Castle)...\n",
            "Fetching data for CSX (CSX Corporation)...\n",
            "Fetching data for CMI (Cummins)...\n",
            "Fetching data for CVS (CVS Health)...\n",
            "Fetching data for DHR (Danaher Corporation)...\n",
            "Fetching data for DRI (Darden Restaurants)...\n",
            "Fetching data for DVA (DaVita)...\n",
            "Fetching data for DAY (Dayforce)...\n",
            "Fetching data for DECK (Deckers Brands)...\n",
            "Fetching data for DE (Deere & Company)...\n",
            "Fetching data for DAL (Delta Air Lines)...\n",
            "Fetching data for DVN (Devon Energy)...\n",
            "Fetching data for DXCM (Dexcom)...\n",
            "Fetching data for FANG (Diamondback Energy)...\n",
            "Fetching data for DLR (Digital Realty)...\n",
            "Fetching data for DFS (Discover Financial)...\n",
            "Fetching data for DG (Dollar General)...\n",
            "Fetching data for DLTR (Dollar Tree)...\n",
            "Fetching data for D (Dominion Energy)...\n",
            "Fetching data for DPZ (Domino's)...\n",
            "Fetching data for DOV (Dover Corporation)...\n",
            "Fetching data for DOW (Dow Inc.)...\n",
            "Fetching data for DHI (DR Horton)...\n",
            "Fetching data for DTE (DTE Energy)...\n",
            "Fetching data for DUK (Duke Energy)...\n",
            "Fetching data for DD (DuPont)...\n",
            "Fetching data for EMN (Eastman Chemical Company)...\n",
            "Fetching data for ETN (Eaton Corporation)...\n",
            "Fetching data for EBAY (eBay)...\n",
            "Fetching data for ECL (Ecolab)...\n",
            "Fetching data for EIX (Edison International)...\n",
            "Fetching data for EW (Edwards Lifesciences)...\n",
            "Fetching data for EA (Electronic Arts)...\n",
            "Fetching data for ELV (Elevance Health)...\n",
            "Fetching data for EMR (Emerson Electric)...\n",
            "Fetching data for ENPH (Enphase)...\n",
            "Fetching data for ETR (Entergy)...\n",
            "Fetching data for EOG (EOG Resources)...\n",
            "Fetching data for EPAM (EPAM Systems)...\n",
            "Fetching data for EQT (EQT Corporation)...\n",
            "Fetching data for EFX (Equifax)...\n",
            "Fetching data for EQIX (Equinix)...\n",
            "Fetching data for EQR (Equity Residential)...\n",
            "Fetching data for ESS (Essex Property Trust)...\n",
            "Fetching data for EL (Estée Lauder Companies (The))...\n",
            "Fetching data for ETSY (Etsy)...\n",
            "Fetching data for EG (Everest Re)...\n",
            "Fetching data for EVRG (Evergy)...\n",
            "Fetching data for ES (Eversource)...\n",
            "Fetching data for EXC (Exelon)...\n",
            "Fetching data for EXPE (Expedia Group)...\n",
            "Fetching data for EXPD (Expeditors International)...\n",
            "Fetching data for EXR (Extra Space Storage)...\n",
            "Fetching data for XOM (ExxonMobil)...\n",
            "Fetching data for FFIV (F5, Inc.)...\n",
            "Fetching data for FDS (FactSet)...\n",
            "Fetching data for FICO (Fair Isaac)...\n",
            "Fetching data for FAST (Fastenal)...\n",
            "Fetching data for FRT (Federal Realty)...\n",
            "Fetching data for FDX (FedEx)...\n",
            "Fetching data for FIS (Fidelity National Information Services)...\n",
            "Fetching data for FITB (Fifth Third Bank)...\n",
            "Fetching data for FSLR (First Solar)...\n",
            "Fetching data for FE (FirstEnergy)...\n",
            "Fetching data for FI (Fiserv)...\n",
            "Fetching data for FMC (FMC Corporation)...\n",
            "Fetching data for F (Ford Motor Company)...\n",
            "Fetching data for FTNT (Fortinet)...\n",
            "Fetching data for FTV (Fortive)...\n",
            "Fetching data for FOXA (Fox Corporation (Class A))...\n",
            "Fetching data for FOX (Fox Corporation (Class B))...\n",
            "Fetching data for BEN (Franklin Templeton)...\n",
            "Fetching data for FCX (Freeport-McMoRan)...\n",
            "Fetching data for GRMN (Garmin)...\n",
            "Fetching data for IT (Gartner)...\n",
            "Fetching data for GE (GE Aerospace)...\n",
            "Fetching data for GEHC (GE HealthCare)...\n",
            "Fetching data for GEV (GE Vernova)...\n",
            "Fetching data for GEN (Gen Digital)...\n",
            "Fetching data for GNRC (Generac)...\n",
            "Fetching data for GD (General Dynamics)...\n",
            "Fetching data for GIS (General Mills)...\n",
            "Fetching data for GM (General Motors)...\n",
            "Fetching data for GPC (Genuine Parts Company)...\n",
            "Fetching data for GILD (Gilead Sciences)...\n",
            "Fetching data for GPN (Global Payments)...\n",
            "Fetching data for GL (Globe Life)...\n",
            "Fetching data for GDDY (GoDaddy)...\n",
            "Fetching data for GS (Goldman Sachs)...\n",
            "Fetching data for HAL (Halliburton)...\n",
            "Fetching data for HIG (Hartford (The))...\n",
            "Fetching data for HAS (Hasbro)...\n",
            "Fetching data for HCA (HCA Healthcare)...\n",
            "Fetching data for DOC (Healthpeak Properties)...\n",
            "Fetching data for HSIC (Henry Schein)...\n",
            "Fetching data for HSY (Hershey Company (The))...\n",
            "Fetching data for HES (Hess Corporation)...\n",
            "Fetching data for HPE (Hewlett Packard Enterprise)...\n",
            "Fetching data for HLT (Hilton Worldwide)...\n",
            "Fetching data for HOLX (Hologic)...\n",
            "Fetching data for HD (Home Depot (The))...\n",
            "Fetching data for HON (Honeywell)...\n",
            "Fetching data for HRL (Hormel Foods)...\n",
            "Fetching data for HST (Host Hotels & Resorts)...\n",
            "Fetching data for HWM (Howmet Aerospace)...\n",
            "Fetching data for HPQ (HP Inc.)...\n",
            "Fetching data for HUBB (Hubbell Incorporated)...\n",
            "Fetching data for HUM (Humana)...\n",
            "Fetching data for HBAN (Huntington Bancshares)...\n",
            "Fetching data for HII (Huntington Ingalls Industries)...\n",
            "Fetching data for IBM (IBM)...\n",
            "Fetching data for IEX (IDEX Corporation)...\n",
            "Fetching data for IDXX (Idexx Laboratories)...\n",
            "Fetching data for ITW (Illinois Tool Works)...\n",
            "Fetching data for INCY (Incyte)...\n",
            "Fetching data for IR (Ingersoll Rand)...\n",
            "Fetching data for PODD (Insulet Corporation)...\n",
            "Fetching data for INTC (Intel)...\n",
            "Fetching data for ICE (Intercontinental Exchange)...\n",
            "Fetching data for IFF (International Flavors & Fragrances)...\n",
            "Fetching data for IP (International Paper)...\n",
            "Fetching data for IPG (Interpublic Group of Companies (The))...\n",
            "Fetching data for INTU (Intuit)...\n",
            "Fetching data for ISRG (Intuitive Surgical)...\n",
            "Fetching data for IVZ (Invesco)...\n",
            "Fetching data for INVH (Invitation Homes)...\n",
            "Fetching data for IQV (IQVIA)...\n",
            "Fetching data for IRM (Iron Mountain)...\n",
            "Fetching data for JBHT (J.B. Hunt)...\n",
            "Fetching data for JBL (Jabil)...\n",
            "Fetching data for JKHY (Jack Henry & Associates)...\n",
            "Fetching data for J (Jacobs Solutions)...\n",
            "Fetching data for JNJ (Johnson & Johnson)...\n",
            "Fetching data for JCI (Johnson Controls)...\n",
            "Fetching data for JPM (JPMorgan Chase)...\n",
            "Fetching data for JNPR (Juniper Networks)...\n",
            "Fetching data for K (Kellanova)...\n",
            "Fetching data for KVUE (Kenvue)...\n",
            "Fetching data for KDP (Keurig Dr Pepper)...\n",
            "Fetching data for KEY (KeyCorp)...\n",
            "Fetching data for KEYS (Keysight)...\n",
            "Fetching data for KMB (Kimberly-Clark)...\n",
            "Fetching data for KIM (Kimco Realty)...\n",
            "Fetching data for KMI (Kinder Morgan)...\n",
            "Fetching data for KKR (KKR)...\n",
            "Fetching data for KLAC (KLA Corporation)...\n",
            "Fetching data for KHC (Kraft Heinz)...\n",
            "Fetching data for KR (Kroger)...\n",
            "Fetching data for LHX (L3Harris)...\n",
            "Fetching data for LH (LabCorp)...\n",
            "Fetching data for LRCX (Lam Research)...\n",
            "Fetching data for LW (Lamb Weston)...\n",
            "Fetching data for LVS (Las Vegas Sands)...\n",
            "Fetching data for LDOS (Leidos)...\n",
            "Fetching data for LEN (Lennar)...\n",
            "Fetching data for LLY (Lilly (Eli))...\n",
            "Fetching data for LIN (Linde plc)...\n",
            "Fetching data for LYV (Live Nation Entertainment)...\n",
            "Fetching data for LKQ (LKQ Corporation)...\n",
            "Fetching data for LMT (Lockheed Martin)...\n",
            "Fetching data for L (Loews Corporation)...\n",
            "Fetching data for LOW (Lowe's)...\n",
            "Fetching data for LULU (Lululemon Athletica)...\n",
            "Fetching data for LYB (LyondellBasell)...\n",
            "Fetching data for MTB (M&T Bank)...\n",
            "Fetching data for MRO (Marathon Oil)...\n",
            "Fetching data for MPC (Marathon Petroleum)...\n",
            "Fetching data for MKTX (MarketAxess)...\n",
            "Fetching data for MAR (Marriott International)...\n",
            "Fetching data for MMC (Marsh McLennan)...\n",
            "Fetching data for MLM (Martin Marietta Materials)...\n",
            "Fetching data for MAS (Masco)...\n",
            "Fetching data for MA (Mastercard)...\n",
            "Fetching data for MTCH (Match Group)...\n",
            "Fetching data for MKC (McCormick & Company)...\n",
            "Fetching data for MCD (McDonald's)...\n",
            "Fetching data for MCK (McKesson Corporation)...\n",
            "Fetching data for MDT (Medtronic)...\n",
            "Fetching data for MRK (Merck & Co.)...\n",
            "Fetching data for META (Meta Platforms)...\n",
            "Fetching data for MET (MetLife)...\n",
            "Fetching data for MTD (Mettler Toledo)...\n",
            "Fetching data for MGM (MGM Resorts)...\n",
            "Fetching data for MCHP (Microchip Technology)...\n",
            "Fetching data for MU (Micron Technology)...\n",
            "Fetching data for MSFT (Microsoft)...\n",
            "Fetching data for MAA (Mid-America Apartment Communities)...\n",
            "Fetching data for MRNA (Moderna)...\n",
            "Fetching data for MHK (Mohawk Industries)...\n",
            "Fetching data for MOH (Molina Healthcare)...\n",
            "Fetching data for TAP (Molson Coors Beverage Company)...\n",
            "Fetching data for MDLZ (Mondelez International)...\n",
            "Fetching data for MPWR (Monolithic Power Systems)...\n",
            "Fetching data for MNST (Monster Beverage)...\n",
            "Fetching data for MCO (Moody's Corporation)...\n",
            "Fetching data for MS (Morgan Stanley)...\n",
            "Fetching data for MOS (Mosaic Company (The))...\n",
            "Fetching data for MSI (Motorola Solutions)...\n",
            "Fetching data for MSCI (MSCI)...\n",
            "Fetching data for NDAQ (Nasdaq, Inc.)...\n",
            "Fetching data for NTAP (NetApp)...\n",
            "Fetching data for NFLX (Netflix)...\n",
            "Fetching data for NEM (Newmont)...\n",
            "Fetching data for NWSA (News Corp (Class A))...\n",
            "Fetching data for NWS (News Corp (Class B))...\n",
            "Fetching data for NEE (NextEra Energy)...\n",
            "Fetching data for NKE (Nike, Inc.)...\n",
            "Fetching data for NI (NiSource)...\n",
            "Fetching data for NDSN (Nordson Corporation)...\n",
            "Fetching data for NSC (Norfolk Southern Railway)...\n",
            "Fetching data for NTRS (Northern Trust)...\n",
            "Fetching data for NOC (Northrop Grumman)...\n",
            "Fetching data for NCLH (Norwegian Cruise Line Holdings)...\n",
            "Fetching data for NRG (NRG Energy)...\n",
            "Fetching data for NUE (Nucor)...\n",
            "Fetching data for NVDA (Nvidia)...\n",
            "Fetching data for NVR (NVR, Inc.)...\n",
            "Fetching data for NXPI (NXP Semiconductors)...\n",
            "Fetching data for ORLY (O'Reilly Auto Parts)...\n",
            "Fetching data for OXY (Occidental Petroleum)...\n",
            "Fetching data for ODFL (Old Dominion)...\n",
            "Fetching data for OMC (Omnicom Group)...\n",
            "Fetching data for ON (ON Semiconductor)...\n",
            "Fetching data for OKE (ONEOK)...\n",
            "Fetching data for ORCL (Oracle Corporation)...\n",
            "Fetching data for OTIS (Otis Worldwide)...\n",
            "Fetching data for PCAR (Paccar)...\n",
            "Fetching data for PKG (Packaging Corporation of America)...\n",
            "Fetching data for PANW (Palo Alto Networks)...\n",
            "Fetching data for PARA (Paramount Global)...\n",
            "Fetching data for PH (Parker Hannifin)...\n",
            "Fetching data for PAYX (Paychex)...\n",
            "Fetching data for PAYC (Paycom)...\n",
            "Fetching data for PYPL (PayPal)...\n",
            "Fetching data for PNR (Pentair)...\n",
            "Fetching data for PEP (PepsiCo)...\n",
            "Fetching data for PFE (Pfizer)...\n",
            "Fetching data for PCG (PG&E Corporation)...\n",
            "Fetching data for PM (Philip Morris International)...\n",
            "Fetching data for PSX (Phillips 66)...\n",
            "Fetching data for PNW (Pinnacle West)...\n",
            "Fetching data for PNC (PNC Financial Services)...\n",
            "Fetching data for POOL (Pool Corporation)...\n",
            "Fetching data for PPG (PPG Industries)...\n",
            "Fetching data for PPL (PPL Corporation)...\n",
            "Fetching data for PFG (Principal Financial Group)...\n",
            "Fetching data for PG (Procter & Gamble)...\n",
            "Fetching data for PGR (Progressive Corporation)...\n",
            "Fetching data for PLD (Prologis)...\n",
            "Fetching data for PRU (Prudential Financial)...\n",
            "Fetching data for PEG (Public Service Enterprise Group)...\n",
            "Fetching data for PTC (PTC)...\n",
            "Fetching data for PSA (Public Storage)...\n",
            "Fetching data for PHM (PulteGroup)...\n",
            "Fetching data for QRVO (Qorvo)...\n",
            "Fetching data for PWR (Quanta Services)...\n",
            "Fetching data for QCOM (Qualcomm)...\n",
            "Fetching data for DGX (Quest Diagnostics)...\n",
            "Fetching data for RL (Ralph Lauren Corporation)...\n",
            "Fetching data for RJF (Raymond James)...\n",
            "Fetching data for RTX (RTX Corporation)...\n",
            "Fetching data for O (Realty Income)...\n",
            "Fetching data for REG (Regency Centers)...\n",
            "Fetching data for REGN (Regeneron)...\n",
            "Fetching data for RF (Regions Financial Corporation)...\n",
            "Fetching data for RSG (Republic Services)...\n",
            "Fetching data for RMD (ResMed)...\n",
            "Fetching data for RVTY (Revvity)...\n",
            "Fetching data for ROK (Rockwell Automation)...\n",
            "Fetching data for ROL (Rollins, Inc.)...\n",
            "Fetching data for ROP (Roper Technologies)...\n",
            "Fetching data for ROST (Ross Stores)...\n",
            "Fetching data for RCL (Royal Caribbean Group)...\n",
            "Fetching data for SPGI (S&P Global)...\n",
            "Fetching data for CRM (Salesforce)...\n",
            "Fetching data for SBAC (SBA Communications)...\n",
            "Fetching data for SLB (Schlumberger)...\n",
            "Fetching data for STX (Seagate Technology)...\n",
            "Fetching data for SRE (Sempra)...\n",
            "Fetching data for NOW (ServiceNow)...\n",
            "Fetching data for SHW (Sherwin-Williams)...\n",
            "Fetching data for SPG (Simon Property Group)...\n",
            "Fetching data for SWKS (Skyworks Solutions)...\n",
            "Fetching data for SJM (J.M. Smucker Company (The))...\n",
            "Fetching data for SW (Smurfit WestRock)...\n",
            "Fetching data for SNA (Snap-on)...\n",
            "Fetching data for SOLV (Solventum)...\n",
            "Fetching data for SO (Southern Company)...\n",
            "Fetching data for LUV (Southwest Airlines)...\n",
            "Fetching data for SWK (Stanley Black & Decker)...\n",
            "Fetching data for SBUX (Starbucks)...\n",
            "Fetching data for STT (State Street Corporation)...\n",
            "Fetching data for STLD (Steel Dynamics)...\n",
            "Fetching data for STE (Steris)...\n",
            "Fetching data for SYK (Stryker Corporation)...\n",
            "Fetching data for SMCI (Supermicro)...\n",
            "Fetching data for SYF (Synchrony Financial)...\n",
            "Fetching data for SNPS (Synopsys)...\n",
            "Fetching data for SYY (Sysco)...\n",
            "Fetching data for TMUS (T-Mobile US)...\n",
            "Fetching data for TROW (T. Rowe Price)...\n",
            "Fetching data for TTWO (Take-Two Interactive)...\n",
            "Fetching data for TPR (Tapestry, Inc.)...\n",
            "Fetching data for TRGP (Targa Resources)...\n",
            "Fetching data for TGT (Target Corporation)...\n",
            "Fetching data for TEL (TE Connectivity)...\n",
            "Fetching data for TDY (Teledyne Technologies)...\n",
            "Fetching data for TFX (Teleflex)...\n",
            "Fetching data for TER (Teradyne)...\n",
            "Fetching data for TSLA (Tesla, Inc.)...\n",
            "Fetching data for TXN (Texas Instruments)...\n",
            "Fetching data for TXT (Textron)...\n",
            "Fetching data for TMO (Thermo Fisher Scientific)...\n",
            "Fetching data for TJX (TJX Companies)...\n",
            "Fetching data for TSCO (Tractor Supply)...\n",
            "Fetching data for TT (Trane Technologies)...\n",
            "Fetching data for TDG (TransDigm Group)...\n",
            "Fetching data for TRV (Travelers Companies (The))...\n",
            "Fetching data for TRMB (Trimble Inc.)...\n",
            "Fetching data for TFC (Truist)...\n",
            "Fetching data for TYL (Tyler Technologies)...\n",
            "Fetching data for TSN (Tyson Foods)...\n",
            "Fetching data for USB (U.S. Bank)...\n",
            "Fetching data for UBER (Uber)...\n",
            "Fetching data for UDR (UDR, Inc.)...\n",
            "Fetching data for ULTA (Ulta Beauty)...\n",
            "Fetching data for UNP (Union Pacific Corporation)...\n",
            "Fetching data for UAL (United Airlines Holdings)...\n",
            "Fetching data for UPS (United Parcel Service)...\n",
            "Fetching data for URI (United Rentals)...\n",
            "Fetching data for UNH (UnitedHealth Group)...\n",
            "Fetching data for UHS (Universal Health Services)...\n",
            "Fetching data for VLO (Valero Energy)...\n",
            "Fetching data for VTR (Ventas)...\n",
            "Fetching data for VLTO (Veralto)...\n",
            "Fetching data for VRSN (Verisign)...\n",
            "Fetching data for VRSK (Verisk)...\n",
            "Fetching data for VZ (Verizon)...\n",
            "Fetching data for VRTX (Vertex Pharmaceuticals)...\n",
            "Fetching data for VTRS (Viatris)...\n",
            "Fetching data for VICI (Vici Properties)...\n",
            "Fetching data for V (Visa Inc.)...\n",
            "Fetching data for VST (Vistra)...\n",
            "Fetching data for VMC (Vulcan Materials Company)...\n",
            "Fetching data for WRB (W. R. Berkley Corporation)...\n",
            "Fetching data for GWW (W. W. Grainger)...\n",
            "Fetching data for WAB (Wabtec)...\n",
            "Fetching data for WBA (Walgreens Boots Alliance)...\n",
            "Fetching data for WMT (Walmart)...\n",
            "Fetching data for DIS (Walt Disney Company (The))...\n",
            "Fetching data for WBD (Warner Bros. Discovery)...\n",
            "Fetching data for WM (Waste Management)...\n",
            "Fetching data for WAT (Waters Corporation)...\n",
            "Fetching data for WEC (WEC Energy Group)...\n",
            "Fetching data for WFC (Wells Fargo)...\n",
            "Fetching data for WELL (Welltower)...\n",
            "Fetching data for WST (West Pharmaceutical Services)...\n",
            "Fetching data for WDC (Western Digital)...\n",
            "Fetching data for WY (Weyerhaeuser)...\n",
            "Fetching data for WMB (Williams Companies)...\n",
            "Fetching data for WTW (Willis Towers Watson)...\n",
            "Fetching data for WYNN (Wynn Resorts)...\n",
            "Fetching data for XEL (Xcel Energy)...\n",
            "Fetching data for XYL (Xylem Inc.)...\n",
            "Fetching data for YUM (Yum! Brands)...\n",
            "Fetching data for ZBRA (Zebra Technologies)...\n",
            "Fetching data for ZBH (Zimmer Biomet)...\n",
            "Fetching data for ZTS (Zoetis)...\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_e40d571c-80d6-4a34-8dc5-18bf9491d71a\", \"sp500_financial_data_with_master_and_industry.xlsx\", 10572829)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data saved to 'sp500_financial_data_with_master_and_industry.xlsx'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "\n",
        "# Function to fetch S&P 500 companies and industries\n",
        "def fetch_sp500_companies():\n",
        "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
        "    sp500_table = pd.read_html(url)\n",
        "    sp500_df = sp500_table[0]\n",
        "    return sp500_df[['Symbol', 'Security', 'GICS Sector', 'Headquarters Location']]\n",
        "\n",
        "# Function to fetch additional company info (e.g., year of establishment)\n",
        "def fetch_company_info(ticker):\n",
        "    stock = yf.Ticker(ticker)\n",
        "    info = stock.info\n",
        "    return {\n",
        "        'Year of Establishment': info.get('yearFounded', None),\n",
        "        'Country': info.get('country', None),\n",
        "        'Region': info.get('region', None)\n",
        "    }\n",
        "\n",
        "# Function to fetch the financials (balance sheet, income statement, and cash flow) for a given stock ticker\n",
        "def fetch_financials(ticker):\n",
        "    try:\n",
        "        stock = yf.Ticker(ticker)\n",
        "        balance_sheet = stock.balance_sheet\n",
        "        income_statement = stock.financials\n",
        "        cash_flow = stock.cashflow\n",
        "        market_cap = stock.info.get('marketCap', None)  # Fetch market cap for ranking\n",
        "        # Fetch equity from balance sheet if available\n",
        "        equity = balance_sheet.loc['Total Stockholder Equity'] if 'Total Stockholder Equity' in balance_sheet.index else None\n",
        "\n",
        "        return balance_sheet, income_statement, cash_flow, market_cap, equity\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching financial data for {ticker}: {e}\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "# Fetch S&P 500 companies\n",
        "sp500_companies = fetch_sp500_companies()\n",
        "\n",
        "# Initialize DataFrames to store data\n",
        "financial_data = pd.DataFrame(columns=['Date', 'Category', 'Stock Code', 'Metric', 'Amount', 'Industry', 'Rank in S&P 500', 'Rank in Industry'])\n",
        "index_data = pd.DataFrame(columns=['Company Name', 'Stock Code', 'Year of Establishment', 'Rank in S&P 500', 'Industry'])\n",
        "industry_summary = pd.DataFrame(columns=['Industry', 'Total Companies', 'Region', 'Country'])\n",
        "\n",
        "# Fetch financials and additional info for each company\n",
        "market_caps = {}\n",
        "\n",
        "for index, row in sp500_companies.iterrows():\n",
        "    symbol = row['Symbol']\n",
        "    company_name = row['Security']\n",
        "    industry = row['GICS Sector']\n",
        "    print(f\"Fetching data for {symbol} ({company_name})...\")\n",
        "\n",
        "    # Fetch company information\n",
        "    company_info = fetch_company_info(symbol)\n",
        "\n",
        "    # Fetch financial data\n",
        "    balance_sheet, income_statement, cash_flow, market_cap, equity = fetch_financials(symbol)\n",
        "\n",
        "    if market_cap:\n",
        "        market_caps[symbol] = (market_cap, industry)\n",
        "\n",
        "    # Add to index data (masterdata sheet)\n",
        "    index_data = pd.concat([index_data, pd.DataFrame({\n",
        "        'Company Name': [company_name],\n",
        "        'Stock Code': [symbol],\n",
        "        'Year of Establishment': [company_info['Year of Establishment']],\n",
        "        'Rank in S&P 500': [None],  # To be filled later\n",
        "        'Industry': [industry]\n",
        "    })], ignore_index=True)\n",
        "\n",
        "    # Process financial data and clean zero or missing values in the 'Amount' column\n",
        "    if balance_sheet is not None and not balance_sheet.empty:\n",
        "        # Iterate through all available columns (years) in the balance sheet\n",
        "        for column in balance_sheet.columns:\n",
        "            for item in balance_sheet.index:\n",
        "                amount = balance_sheet.loc[item, column]\n",
        "                if pd.notnull(amount) and amount != 0:  # Exclude missing or zero values\n",
        "                    financial_data = pd.concat([financial_data, pd.DataFrame({\n",
        "                        'Date': [column],  # Use the reporting date\n",
        "                        'Category': ['Balance Sheet'],\n",
        "                        'Stock Code': [symbol],\n",
        "                        'Metric': [item],\n",
        "                        'Amount': [amount],\n",
        "                        'Industry': [industry],\n",
        "                        'Rank in S&P 500': [None],  # To be filled later\n",
        "                        'Rank in Industry': [None]  # To be filled later\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "    if income_statement is not None and not income_statement.empty:\n",
        "        for column in income_statement.columns:\n",
        "            for item in income_statement.index:\n",
        "                amount = income_statement.loc[item, column]\n",
        "                if pd.notnull(amount) and amount != 0:  # Exclude missing or zero values\n",
        "                    financial_data = pd.concat([financial_data, pd.DataFrame({\n",
        "                        'Date': [column],  # Use the reporting date\n",
        "                        'Category': ['Income Statement'],\n",
        "                        'Stock Code': [symbol],\n",
        "                        'Metric': [item],\n",
        "                        'Amount': [amount],\n",
        "                        'Industry': [industry],\n",
        "                        'Rank in S&P 500': [None],  # To be filled later\n",
        "                        'Rank in Industry': [None]  # To be filled later\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "    if cash_flow is not None and not cash_flow.empty:\n",
        "        for column in cash_flow.columns:\n",
        "            for item in cash_flow.index:\n",
        "                amount = cash_flow.loc[item, column]\n",
        "                if pd.notnull(amount) and amount != 0:  # Exclude missing or zero values\n",
        "                    financial_data = pd.concat([financial_data, pd.DataFrame({\n",
        "                        'Date': [column],  # Use the reporting date\n",
        "                        'Category': ['Cash Flow'],\n",
        "                        'Stock Code': [symbol],\n",
        "                        'Metric': [item],\n",
        "                        'Amount': [amount],\n",
        "                        'Industry': [industry],\n",
        "                        'Rank in S&P 500': [None],  # To be filled later\n",
        "                        'Rank in Industry': [None]  # To be filled later\n",
        "                    })], ignore_index=True)\n",
        "\n",
        "    if equity is not None and pd.notnull(equity) and equity != 0:\n",
        "        # Add Equity data\n",
        "        new_row = pd.DataFrame({\n",
        "            'Date': [column],  # Use the reporting date\n",
        "            'Category': ['Equity'],\n",
        "            'Stock Code': [symbol],\n",
        "            'Metric': ['Total Stockholder Equity'],\n",
        "            'Amount': [equity],\n",
        "            'Industry': [industry],\n",
        "            'Rank in S&P 500': [None],  # To be filled later\n",
        "            'Rank in Industry': [None]  # To be filled later\n",
        "        })\n",
        "        financial_data = pd.concat([financial_data, new_row], ignore_index=True)\n",
        "\n",
        "# Calculate Rank in S&P 500 based on Market Cap\n",
        "sorted_market_caps = sorted(market_caps.items(), key=lambda x: x[1][0], reverse=True)\n",
        "rank_in_sp500 = {symbol: rank + 1 for rank, (symbol, _) in enumerate(sorted_market_caps)}\n",
        "\n",
        "# Calculate Rank in Industry based on Market Cap\n",
        "industry_groups = {}\n",
        "for symbol, (market_cap, industry) in market_caps.items():\n",
        "    if industry not in industry_groups:\n",
        "        industry_groups[industry] = []\n",
        "    industry_groups[industry].append((symbol, market_cap))\n",
        "\n",
        "rank_in_industry = {}\n",
        "for industry, companies in industry_groups.items():\n",
        "    sorted_industry = sorted(companies, key=lambda x: x[1], reverse=True)\n",
        "    for rank, (symbol, _) in enumerate(sorted_industry):\n",
        "        rank_in_industry[symbol] = rank + 1\n",
        "\n",
        "# Update ranks in the DataFrame\n",
        "financial_data['Rank in S&P 500'] = financial_data['Stock Code'].map(rank_in_sp500)\n",
        "financial_data['Rank in Industry'] = financial_data['Stock Code'].map(rank_in_industry)\n",
        "\n",
        "# Save everything to Excel\n",
        "with pd.ExcelWriter('sp500_financial_data_with_master_and_industry.xlsx', engine='xlsxwriter') as writer:\n",
        "    financial_data.to_excel(writer, sheet_name='FinancialData', index=False)\n",
        "    index_data.to_excel(writer, sheet_name='Index', index=False)\n",
        "    industry_summary.to_excel(writer, sheet_name='IndustrySummary', index=False)\n",
        "\n",
        "print(\"Data saved to 'sp500_financial_data_with_master_and_industry.xlsx'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PUtsBzkCkhWZ",
        "outputId": "59613a68-fe55-4eb1-be6a-1369eb24ef8d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_daf7fe22-adf1-4747-bbde-845a910681ba\", \"sp500_financial_data_with_master_and_industry.xlsx\", 2806434)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the Excel file to your local machine\n",
        "files.download('sp500_financial_data_with_master_and_industry.xlsx')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}